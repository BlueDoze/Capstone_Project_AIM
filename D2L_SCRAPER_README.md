# D2L Event Scraper - Guia de Uso

## üìã Vis√£o Geral

O D2L Event Scraper √© um m√≥dulo automatizado que extrai eventos da plataforma Fanshawe Online (D2L/Brightspace). Ele usa Playwright para navega√ß√£o autenticada e pode ser testado isoladamente antes de integrar com o sistema principal.

## üéØ Funcionalidades

- ‚úÖ Login autom√°tico no D2L com credenciais seguras
- ‚úÖ Navega√ß√£o em p√°ginas de cursos espec√≠ficos
- ‚úÖ Extra√ß√£o de eventos com m√∫ltiplas estrat√©gias de parsing
- ‚úÖ Suporte a diferentes formatos de data/hora
- ‚úÖ Captura de screenshots para debug
- ‚úÖ Modo interativo (visualizar navegador)
- ‚úÖ Exporta√ß√£o para JSON compat√≠vel com `campus_events.json`
- ‚úÖ Logging detalhado para troubleshooting

## üìÅ Arquivos Criados

```
Capstone_Project_AIM/
‚îú‚îÄ‚îÄ src/services/
‚îÇ   ‚îî‚îÄ‚îÄ d2l_scraper.py          # M√≥dulo principal do scraper
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_d2l_scraper.py     # Script de teste isolado
‚îú‚îÄ‚îÄ .env.example                 # Template de configura√ß√£o
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias (atualizado)
‚îî‚îÄ‚îÄ D2L_SCRAPER_README.md       # Este arquivo
```

## üöÄ Instala√ß√£o

### 1. Instalar Depend√™ncias

```bash
# Instalar pacotes Python
pip install -r requirements.txt

# Instalar navegador Chromium para Playwright
playwright install chromium
```

### 2. Configurar Credenciais

```bash
# Copiar template de configura√ß√£o
cp .env.example .env

# Editar .env e adicionar suas credenciais
nano .env  # ou use seu editor preferido
```

**Arquivo .env:**
```env
D2L_USERNAME=seu_username_fanshawe
D2L_PASSWORD=sua_senha_fanshawe
GEMINI_API_KEY=sua_chave_gemini
```

‚ö†Ô∏è **IMPORTANTE**: Nunca fa√ßa commit do arquivo `.env` com credenciais reais!

## üß™ Teste Isolado

O scraper pode ser testado **completamente isolado** do sistema principal:

```bash
python tests/test_d2l_scraper.py
```

### Menu de Testes Dispon√≠veis

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    D2L EVENT SCRAPER - TESTE ISOLADO                         ‚ïë
‚ïë                        Fanshawe Navigator Project                            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Op√ß√µes dispon√≠veis:
  1. Teste b√°sico de scraping
  2. Scraping com screenshot (para debug)
  3. Teste com ID de curso customizado
  4. Executar todos os testes
  5. Modo interativo (visualizar navegador)
  0. Sair
```

### Descri√ß√£o dos Testes

#### 1Ô∏è‚É£ Teste B√°sico
- Executa login e scraping padr√£o
- Extrai eventos do curso ID 2001540
- Exibe eventos no terminal
- Op√ß√£o de salvar em JSON

#### 2Ô∏è‚É£ Scraping com Screenshot
- Igual ao teste b√°sico
- **+ Captura screenshot** da p√°gina para debug
- Salva em `data/d2l_screenshot.png`
- √ötil para identificar estrutura HTML

#### 3Ô∏è‚É£ Curso Customizado
- Permite testar com qualquer ID de curso D2L
- Voc√™ fornece o course_id via input
- Exemplo: `2001541`, `2002340`, etc.

#### 4Ô∏è‚É£ Todos os Testes
- Executa testes 1 e 2 sequencialmente
- Compila todos os eventos
- Salva resultado consolidado

#### 5Ô∏è‚É£ Modo Interativo
- **Abre navegador vis√≠vel** (n√£o-headless)
- Voc√™ pode VER o processo acontecendo
- √ötil para debugging visual
- Ver onde o scraper clica e navega

## üíª Uso Program√°tico

### Exemplo B√°sico

```python
import asyncio
from src.services.d2l_scraper import D2LEventScraper

async def main():
    # Criar scraper (credenciais do .env)
    scraper = D2LEventScraper()

    # Executar scraping
    events = await scraper.scrape_events(course_id="2001540")

    # Processar eventos
    for event in events:
        print(f"Evento: {event['name']}")
        print(f"Data: {event['date']}")
        print(f"Local: {event['location']}\n")

if __name__ == "__main__":
    asyncio.run(main())
```

### Exemplo com Screenshot

```python
import asyncio
from src.services.d2l_scraper import D2LEventScraper

async def main():
    scraper = D2LEventScraper()

    # Scraping + screenshot para debug
    events, screenshot_path = await scraper.scrape_with_screenshot(
        course_id="2001540",
        screenshot_path="debug_page.png"
    )

    print(f"Screenshot salvo em: {screenshot_path}")
    print(f"Total de eventos: {len(events)}")

asyncio.run(main())
```

### Exemplo com Credenciais Customizadas

```python
import asyncio
from src.services.d2l_scraper import D2LEventScraper

async def main():
    # Passar credenciais diretamente (sem .env)
    scraper = D2LEventScraper(
        username="meu_user",
        password="minha_senha",
        headless=False  # Mostrar navegador
    )

    events = await scraper.scrape_events()
    return events

asyncio.run(main())
```

## üîß Troubleshooting

### Erro: "Credenciais n√£o fornecidas"

**Solu√ß√£o:**
```bash
# Verificar se .env existe
ls -la .env

# Se n√£o existir, criar a partir do template
cp .env.example .env

# Editar e adicionar credenciais
nano .env
```

### Erro: "Campo de username n√£o encontrado"

**Problema:** Seletores HTML mudaram ou p√°gina n√£o carregou

**Solu√ß√£o:**
```bash
# Executar em modo interativo para ver a p√°gina
python tests/test_d2l_scraper.py
# Escolher op√ß√£o 5 (Modo Interativo)
```

**Ou capturar screenshot:**
```bash
# Op√ß√£o 2 do menu
# Analise o screenshot em data/d2l_screenshot.png
```

### Erro: "Login falhou - ainda na p√°gina de login"

**Poss√≠veis causas:**
- Credenciais incorretas
- D2L mudou fluxo de login (SSO, captcha, etc.)
- Sess√£o expirada

**Solu√ß√£o:**
```bash
# 1. Verificar credenciais manualmente
# Login manual em: https://www.fanshaweonline.ca/d2l/login

# 2. Executar em modo N√ÉO-headless para ver o que acontece
# Edite d2l_scraper.py temporariamente:
# headless=False

# 3. Verificar se D2L adicionou autentica√ß√£o de dois fatores
```

### Nenhum Evento Encontrado

**Poss√≠veis raz√µes:**
1. A p√°gina realmente n√£o tem eventos no momento
2. Eventos est√£o em outra se√ß√£o/aba
3. Seletores HTML precisam ajuste

**Solu√ß√£o:**
```python
# Capturar screenshot para an√°lise
scraper = D2LEventScraper()
events, screenshot = await scraper.scrape_with_screenshot()

# Analise o screenshot e ajuste seletores em:
# src/services/d2l_scraper.py -> m√©todo _extract_events()
```

### Erro: "playwright n√£o instalado"

```bash
pip install playwright
playwright install chromium
```

## üîê Seguran√ßa

### Boas Pr√°ticas

‚úÖ **FA√áA:**
- Use vari√°veis de ambiente (`.env`)
- Adicione `.env` ao `.gitignore`
- Armazene credenciais de forma segura
- Use HTTPS para comunica√ß√£o
- Implemente rate limiting
- Adicione timeouts adequados

‚ùå **N√ÉO FA√áA:**
- Commit de credenciais no c√≥digo
- Hardcode de senhas
- Compartilhar arquivo `.env`
- Fazer scraping agressivo (risco de ban)

### Rate Limiting

O scraper j√° implementa delays autom√°ticos:
- Aguarda `networkidle` antes de extrair
- Delay de 2 segundos ap√≥s carregar conte√∫do
- Timeouts de 30 segundos por opera√ß√£o

## üìä Formato de Sa√≠da

### Estrutura JSON

```json
{
  "metadata": {
    "source": "d2l_scraper",
    "scraped_at": "2025-11-18T14:30:00",
    "total_events": 5,
    "scraper_version": "1.0.0"
  },
  "events": [
    {
      "name": "Workshop de Python",
      "date": "2025-11-25",
      "time": "14:00 PM",
      "location": "Room SC 2013",
      "description": "Workshop introdut√≥rio sobre Python para iniciantes...",
      "category": "academic",
      "source": "d2l_scraper",
      "scraped_at": "2025-11-18T14:30:00"
    }
  ]
}
```

### Campos Extra√≠dos

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `name` | string | Nome do evento |
| `date` | string | Data (m√∫ltiplos formatos suportados) |
| `time` | string | Hor√°rio ou "All Day" |
| `location` | string | Localiza√ß√£o f√≠sica ou "Online" |
| `description` | string | Descri√ß√£o completa (at√© 200 chars) |
| `category` | string | Categoria (padr√£o: "academic") |
| `source` | string | Sempre "d2l_scraper" |
| `scraped_at` | string | Timestamp ISO 8601 |

## üîÑ Integra√ß√£o com Sistema Principal

### Op√ß√£o 1: Endpoint Flask (Recomendado)

Adicione ao `main.py`:

```python
from src.services.d2l_scraper import D2LEventScraper
import asyncio

@app.route("/api/events/refresh-d2l", methods=['POST'])
def refresh_d2l_events():
    """Atualiza eventos do D2L"""
    try:
        scraper = D2LEventScraper()
        events = asyncio.run(scraper.scrape_events())

        # Merge com eventos existentes
        with open('data/campus_events.json', 'r') as f:
            existing_data = json.load(f)

        existing_data['events'].extend(events)

        with open('data/campus_events.json', 'w') as f:
            json.dump(existing_data, f, indent=2)

        return jsonify({
            "status": "success",
            "message": f"{len(events)} eventos adicionados",
            "count": len(events)
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
```

### Op√ß√£o 2: Scheduled Job (Celery/APScheduler)

```python
from apscheduler.schedulers.background import BackgroundScheduler
from src.services.d2l_scraper import D2LEventScraper
import asyncio

def scheduled_scrape():
    """Executa scraping agendado"""
    scraper = D2LEventScraper()
    events = asyncio.run(scraper.scrape_events())
    # Salvar em banco/arquivo

scheduler = BackgroundScheduler()
scheduler.add_job(scheduled_scrape, 'interval', hours=6)
scheduler.start()
```

### Op√ß√£o 3: Ferramenta do Agente Gemini

Adicione como ferramenta dispon√≠vel para o chatbot:

```python
def get_latest_d2l_events():
    """Fun√ß√£o cham√°vel pelo agente Gemini"""
    scraper = D2LEventScraper()
    events = asyncio.run(scraper.scrape_events())
    return events

# Registrar como ferramenta no Gemini function calling
```

## üìù Customiza√ß√£o

### Ajustar Seletores HTML

Se a estrutura da p√°gina D2L mudar, edite os seletores em:

**[src/services/d2l_scraper.py:169-180](src/services/d2l_scraper.py#L169-L180)**

```python
calendar_selectors = [
    ".d2l-calendar-event",
    "[class*='calendar'][class*='event']",
    "[class*='upcoming-event']",
    # Adicione novos seletores aqui
]
```

### Adicionar Novos Campos

Edite o m√©todo `_parse_event_element()`:

**[src/services/d2l_scraper.py:253-291](src/services/d2l_scraper.py#L253-L291)**

```python
event = {
    "name": title,
    "date": extracted_date,
    # Adicione novos campos aqui
    "organizer": extracted_organizer,
    "cost": extracted_cost,
}
```

## üêõ Debug Avan√ßado

### Logs Detalhados

O scraper j√° inclui logging extensivo:

```
[D2L Scraper] Iniciando scraping para curso 2001540...
[D2L Scraper] Fazendo login...
[D2L Scraper] Campo username encontrado: input[name='userName']
[D2L Scraper] Campo password encontrado: input[name='password']
[D2L Scraper] Login completado. URL atual: https://...
[D2L Scraper] Navegando para curso 2001540...
[D2L Scraper] P√°gina do curso carregada!
[D2L Scraper] Extraindo eventos da p√°gina...
[D2L Scraper] Encontrados 3 elementos com seletor: .d2l-calendar-event
[D2L Scraper] Evento 1 extra√≠do: Workshop de Python...
[D2L Scraper] 3 eventos extra√≠dos com sucesso!
```

### Capturar HTML da P√°gina

```python
async with async_playwright() as p:
    browser = await p.chromium.launch()
    page = await browser.new_page()
    # ... login e navega√ß√£o ...

    # Salvar HTML completo
    html = await page.content()
    with open("page_source.html", "w") as f:
        f.write(html)
```

## üìö Refer√™ncias

- [Playwright Python Docs](https://playwright.dev/python/)
- [D2L Brightspace](https://www.d2l.com/)
- [Fanshawe Online](https://www.fanshaweonline.ca/)

## ü§ù Contribuindo

Para melhorar o scraper:

1. Teste com diferentes cursos
2. Identifique novos padr√µes HTML
3. Adicione seletores robustos
4. Melhore tratamento de erros

## ‚öñÔ∏è Considera√ß√µes Legais

‚ö†Ô∏è **IMPORTANTE:**

- Este scraper √© para uso **educacional** apenas
- Obtenha **autoriza√ß√£o** do departamento de TI da Fanshawe
- Respeite os **Termos de Servi√ßo** do D2L
- N√£o use para scraping em massa ou comercial
- Implemente **rate limiting** adequado
- N√£o compartilhe dados pessoais de outros usu√°rios

## üìû Suporte

Se encontrar problemas:

1. Verifique logs detalhados
2. Capture screenshot da p√°gina
3. Execute em modo interativo (op√ß√£o 5)
4. Verifique se credenciais est√£o corretas
5. Teste login manual primeiro

---

**Desenvolvido para o Fanshawe Navigator Project**
*Vers√£o 1.0.0 - Novembro 2025*
