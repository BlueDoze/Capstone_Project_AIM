# ğŸ“ Project Reorganization Plan

## ğŸ¯ Goal
Transform the root directory from 80+ files into a clean, professional structure.

## ğŸ—ï¸ Proposed Architecture: **Feature-Based Modular**

Better than DDD for this project because:
- âœ… Simpler and more practical for scrapers + API + RAG
- âœ… Easy to understand and maintain  
- âœ… Groups related code by feature
- âœ… Avoids DDD over-engineering

---

## ğŸ“‚ NEW STRUCTURE

```
Capstone_Project_AIM/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                          # Main project documentation
â”œâ”€â”€ ğŸ“„ pyproject.toml                     # Python project config
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Dependencies
â”œâ”€â”€ ğŸ“„ uv.lock                            # Lock file
â”œâ”€â”€ ğŸ“„ .env.example                       # Environment template
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ docker-compose.yml
â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“ docs/                              # ALL DOCUMENTATION HERE
â”‚   â”œâ”€â”€ README.md                         # Docs index
â”‚   â”œâ”€â”€ architecture/
â”‚   â”‚   â”œâ”€â”€ system_overview.md
â”‚   â”‚   â””â”€â”€ professor_architecture_visual.md
â”‚   â”œâ”€â”€ guides/
â”‚   â”‚   â”œâ”€â”€ announcements_integration.md
â”‚   â”‚   â”œâ”€â”€ announcements_usage.md
â”‚   â”‚   â”œâ”€â”€ professor_extraction.md
â”‚   â”‚   â”œâ”€â”€ quick_start_announcements.md
â”‚   â”‚   â””â”€â”€ quick_start_multi_course.md
â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â”œâ”€â”€ d2l_agent_integration.md
â”‚   â”‚   â”œâ”€â”€ d2l_scraper_readme.md
â”‚   â”‚   â””â”€â”€ sharepoint_scraper.md
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ endpoints.md
â”‚
â”œâ”€â”€ ğŸ“ src/                               # MAIN APPLICATION CODE
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ scrapers/                      # Feature: Web Scraping
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py              # Abstract base class
â”‚   â”‚   â”œâ”€â”€ d2l/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ announcements.py         # extract_all_announcements.py â†’ here
â”‚   â”‚   â”‚   â”œâ”€â”€ content_home.py          # extract_content_home.py â†’ here
â”‚   â”‚   â”‚   â”œâ”€â”€ professor_info.py        # extract_professor_info.py â†’ here
â”‚   â”‚   â”‚   â””â”€â”€ auth.py                  # 2FA, login logic shared
â”‚   â”‚   â”œâ”€â”€ sharepoint/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ events.py                # extract_sharepoint_events.py â†’ here
â”‚   â”‚   â”‚   â””â”€â”€ auth.py                  # SharePoint auth
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ browser.py               # Playwright setup
â”‚   â”‚       â””â”€â”€ parser.py                # HTML parsing utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api/                           # Feature: REST API (Flask)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                       # main.py â†’ here (Flask app)
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ announcements.py
â”‚   â”‚   â”‚   â”œâ”€â”€ professors.py
â”‚   â”‚   â”‚   â”œâ”€â”€ events.py
â”‚   â”‚   â”‚   â””â”€â”€ navigation.py
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ cors.py
â”‚   â”‚   â””â”€â”€ schemas/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ response_models.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ services/                      # Business Logic Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ announcement_transformer.py  # Keep as is
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ professor_service.py
â”‚   â”‚   â””â”€â”€ event_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ navigation/                    # Feature: Indoor Navigation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ route_planner.py
â”‚   â”‚   â”œâ”€â”€ map_processor.py
â”‚   â”‚   â””â”€â”€ validators/
â”‚   â”‚       â””â”€â”€ route_validator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ embeddings/                    # Feature: RAG / Embeddings
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ generator.py                 # update_embeddings.py logic
â”‚   â”‚   â”œâ”€â”€ validator.py                 # validate_map_embeddings.py
â”‚   â”‚   â””â”€â”€ rag_engine.py                # multimodal_rag_complete.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ database/                      # Data Access Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ announcement_repo.py
â”‚   â”‚   â”‚   â”œâ”€â”€ professor_repo.py
â”‚   â”‚   â”‚   â””â”€â”€ event_repo.py
â”‚   â”‚   â””â”€â”€ cache/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ cache_manager.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                        # Data Models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ announcement.py
â”‚   â”‚   â”œâ”€â”€ professor.py
â”‚   â”‚   â”œâ”€â”€ event.py
â”‚   â”‚   â””â”€â”€ navigation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ config/                        # Configuration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ settings.py                  # Centralized config
â”‚   â”‚   â””â”€â”€ constants.py
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ utils/                         # Shared Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ file_handler.py
â”‚       â””â”€â”€ date_parser.py
â”‚
â”œâ”€â”€ ğŸ“ scripts/                           # Standalone Scripts
â”‚   â”œâ”€â”€ setup_environment.py             # Keep
â”‚   â”œâ”€â”€ run_tests.py                     # Keep
â”‚   â”œâ”€â”€ scrape_all.py                    # New: run all scrapers
â”‚   â”œâ”€â”€ process_course.py                # Move here
â”‚   â”œâ”€â”€ transform_cache.py               # Move here
â”‚   â””â”€â”€ debug/
â”‚       â”œâ”€â”€ debug_login.py               # debug_login_page.py â†’ here
â”‚       â”œâ”€â”€ debug_announcement.py        # Keep
â”‚       â”œâ”€â”€ debug_professor.py           # New if needed
â”‚       â””â”€â”€ debug_sharepoint.py          # debug_sharepoint_page.py â†’ here
â”‚
â”œâ”€â”€ ğŸ“ tests/                             # Test Suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                      # Pytest fixtures
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_scrapers.py
â”‚   â”‚   â”œâ”€â”€ test_services.py
â”‚   â”‚   â””â”€â”€ test_models.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_api.py
â”‚   â”‚   â”œâ”€â”€ test_professor_integration.py  # Move here
â”‚   â”‚   â””â”€â”€ test_announcements_chat.py     # Move here
â”‚   â””â”€â”€ e2e/
â”‚       â””â”€â”€ test_workflow.py
â”‚
â”œâ”€â”€ ğŸ“ data/                              # Data Storage (Keep as is)
â”‚   â”œâ”€â”€ announcements/
â”‚   â”œâ”€â”€ professors/
â”‚   â”œâ”€â”€ sharepoint_events/
â”‚   â””â”€â”€ embeddings/
â”‚
â”œâ”€â”€ ğŸ“ static/                            # Static Assets (Keep)
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ ğŸ“ templates/                         # HTML Templates (Keep)
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ ğŸ“ maps/                              # Map Data (Keep)
â”‚   â””â”€â”€ building_data/
â”‚
â”œâ”€â”€ ğŸ“ tools/                             # Development Tools
â”‚   â”œâ”€â”€ route_generator.py               # generate_route_templates.py â†’ here
â”‚   â”œâ”€â”€ route_viewer.py                  # generate_route_viewer.py â†’ here
â”‚   â””â”€â”€ diagnostics/
â”‚       â”œâ”€â”€ diagnose_routes.py           # Move here
â”‚       â”œâ”€â”€ check_map_routes.py          # Move here
â”‚       â””â”€â”€ list_routes.py               # Move here
â”‚
â””â”€â”€ ğŸ“ temp/                              # Temporary files (gitignored)
    â””â”€â”€ .gitkeep
```

---

## ğŸ”„ MIGRATION STEPS

### **Phase 1: Documentation** âœ…
```bash
mkdir -p docs/{architecture,guides,scraping,api}
mv *.md docs/guides/  # All MD files except README.md
mv docs/guides/README.md ./  # Keep main README in root
```

### **Phase 2: Scrapers** ğŸ”§
```bash
# D2L Scrapers
mkdir -p src/scrapers/d2l
mv extract_all_announcements.py src/scrapers/d2l/announcements.py
mv extract_content_home.py src/scrapers/d2l/content_home.py
mv extract_professor_info.py src/scrapers/d2l/professor_info.py

# SharePoint Scrapers
mkdir -p src/scrapers/sharepoint
mv extract_sharepoint_events.py src/scrapers/sharepoint/events.py
```

### **Phase 3: API** ğŸŒ
```bash
mv main.py src/api/app.py
# Refactor routes into src/api/routes/
```

### **Phase 4: Scripts & Tools** ğŸ“œ
```bash
# Debug scripts
mkdir -p scripts/debug
mv debug_*.py scripts/debug/

# Processing scripts
mv process_course.py scripts/
mv transform_cache.py scripts/

# Tools
mv generate_*.py tools/
mv diagnose_*.py tools/diagnostics/
mv check_*.py tools/diagnostics/
mv list_*.py tools/diagnostics/
```

### **Phase 5: Tests** ğŸ§ª
```bash
mkdir -p tests/{unit,integration,e2e}
mv test_*.py tests/integration/
```

### **Phase 6: Cleanup** ğŸ§¹
```bash
# Remove debug artifacts
rm debug_*.html debug_*.png login_page_debug.* error_screenshot.png

# Remove old JSON files from root (move to data/)
mv *.json data/legacy/  # If needed
```

---

## ğŸ¯ BENEFITS

### Before (Current):
- âŒ 80+ files in root directory
- âŒ Hard to find specific functionality
- âŒ Mixing concerns (scrapers + API + tools)
- âŒ Documentation scattered

### After (Proposed):
- âœ… ~15 files in root (clean!)
- âœ… Clear separation by feature
- âœ… Easy to navigate (`src/scrapers/`, `src/api/`, etc.)
- âœ… All docs in one place
- âœ… Tests properly organized
- âœ… Scalable structure for future growth

---

## ğŸš€ IMPLEMENTATION ORDER

1. **Create directory structure** (5 min)
2. **Move documentation** (10 min) - Safest first step
3. **Move scripts & tools** (15 min) - No code changes
4. **Move scrapers** (20 min) - Update imports
5. **Refactor API** (30 min) - Split routes
6. **Move tests** (10 min)
7. **Update all imports** (20 min)
8. **Test everything** (30 min)
9. **Update README with new structure** (15 min)

**Total estimated time: ~2.5 hours**

---

## ğŸ“ NOTES

- **Imports will need updating**: Use relative imports within `src/`
- **Keep backwards compatibility**: Create symlinks if needed temporarily
- **Git tracking**: Use `git mv` to preserve history
- **Commit frequently**: One commit per phase

---

## â“ WHY NOT DDD?

DDD (Domain-Driven Design) would add:
- `domain/entities/`, `domain/value_objects/`, `domain/aggregates/`
- `application/use_cases/`, `application/commands/`
- `infrastructure/repositories/`, `infrastructure/external_services/`

**Too complex for:**
- Web scraping project (not a complex business domain)
- Small team / solo developer
- Rapid prototyping needs

**Current approach is better:** Clean, simple, feature-focused modules.
